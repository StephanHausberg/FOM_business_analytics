{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means vs. KNN: Comprehensive Comparison\n",
    "\n",
    "This notebook demonstrates the key differences between K-Means Clustering and K-Nearest Neighbors (KNN) through practical examples.\n",
    "\n",
    "## Overview\n",
    "- **K-Means**: Unsupervised clustering algorithm\n",
    "- **KNN**: Supervised learning algorithm for classification and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install numpy pandas matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.datasets import make_classification, make_regression, make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, silhouette_score\n",
    "from sklearn.impute import KNNImputer\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. K-Means: Unsupervised Clustering\n",
    "\n",
    "K-Means groups data into clusters without using labels. It's useful for discovering patterns in unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data for clustering\n",
    "X_clusters, y_true = make_blobs(n_samples=300, centers=4, n_features=2, \n",
    "                                 cluster_std=0.60, random_state=42)\n",
    "\n",
    "# Apply K-Means\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "y_kmeans = kmeans.fit_predict(X_clusters)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Original data (without labels - unsupervised scenario)\n",
    "axes[0].scatter(X_clusters[:, 0], X_clusters[:, 1], c='gray', alpha=0.5, s=50)\n",
    "axes[0].set_title('Original Data (Unlabeled)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "\n",
    "# K-Means clustering result\n",
    "axes[1].scatter(X_clusters[:, 0], X_clusters[:, 1], c=y_kmeans, cmap='viridis', s=50)\n",
    "axes[1].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
    "                c='red', marker='X', s=300, edgecolors='black', linewidths=2, label='Centroids')\n",
    "axes[1].set_title('K-Means Clustering (k=4)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Feature 1')\n",
    "axes[1].set_ylabel('Feature 2')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Silhouette Score: {silhouette_score(X_clusters, y_kmeans):.3f}\")\n",
    "print(\"\\nâœ“ K-Means discovers patterns in unlabeled data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. KNN: Classification (Supervised Learning)\n",
    "\n",
    "KNN predicts the class of a new point based on the classes of its k nearest neighbors. It requires labeled training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification dataset\n",
    "X_class, y_class = make_classification(n_samples=400, n_features=2, n_redundant=0, \n",
    "                                        n_informative=2, n_clusters_per_class=1,\n",
    "                                        random_state=42, flip_y=0.05)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_class, y_class, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train KNN classifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = knn_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Create mesh for decision boundary\n",
    "h = 0.02\n",
    "x_min, x_max = X_class[:, 0].min() - 1, X_class[:, 0].max() + 1\n",
    "y_min, y_max = X_class[:, 1].min() - 1, X_class[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = knn_clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Training data\n",
    "axes[0].scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='coolwarm', \n",
    "                edgecolors='black', s=50, alpha=0.7)\n",
    "axes[0].set_title('Training Data (Labeled)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "\n",
    "# Decision boundary and test predictions\n",
    "axes[1].contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')\n",
    "axes[1].scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='coolwarm', \n",
    "                edgecolors='black', s=50, alpha=0.8, label='True Labels')\n",
    "axes[1].set_title(f'KNN Classification (k=5) - Accuracy: {accuracy:.3f}', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Feature 1')\n",
    "axes[1].set_ylabel('Feature 2')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.3f}\")\n",
    "print(\"\\nâœ“ KNN uses labeled data to predict new samples!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. KNN: Regression\n",
    "\n",
    "KNN can also predict continuous values by averaging the target values of k nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate regression dataset\n",
    "X_reg = np.sort(5 * np.random.rand(200, 1), axis=0)\n",
    "y_reg = np.sin(X_reg).ravel() + np.random.normal(0, 0.1, X_reg.shape[0])\n",
    "\n",
    "# Split data\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train KNN regressor with different k values\n",
    "k_values = [1, 5, 20]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "X_test_sorted = np.linspace(0, 5, 300)[:, np.newaxis]\n",
    "\n",
    "for idx, k in enumerate(k_values):\n",
    "    knn_reg = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn_reg.fit(X_train_reg, y_train_reg)\n",
    "    y_pred_reg = knn_reg.predict(X_test_sorted)\n",
    "    \n",
    "    # Calculate MSE on test set\n",
    "    y_test_pred = knn_reg.predict(X_test_reg)\n",
    "    mse = mean_squared_error(y_test_reg, y_test_pred)\n",
    "    \n",
    "    axes[idx].scatter(X_train_reg, y_train_reg, c='blue', s=20, alpha=0.5, label='Training Data')\n",
    "    axes[idx].plot(X_test_sorted, y_pred_reg, c='red', linewidth=2, label='KNN Prediction')\n",
    "    axes[idx].set_title(f'KNN Regression (k={k})\\nMSE: {mse:.3f}', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('X')\n",
    "    axes[idx].set_ylabel('y')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ KNN regression averages k nearest neighbors' values!\")\n",
    "print(\"Note: Smaller k = more flexible (may overfit), Larger k = smoother predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Missing Value Imputation\n",
    "\n",
    "Both K-Means and KNN can be used for imputing missing values, but KNN is more commonly used and often more effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset with missing values\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "X_complete = np.random.randn(n_samples, 3) * 10 + 50\n",
    "X_complete[:, 1] = X_complete[:, 0] * 0.8 + np.random.randn(n_samples) * 5  # Create correlation\n",
    "\n",
    "# Introduce missing values (15% of data)\n",
    "X_missing = X_complete.copy()\n",
    "missing_mask = np.random.random(X_missing.shape) < 0.15\n",
    "X_missing[missing_mask] = np.nan\n",
    "\n",
    "print(f\"Total values: {X_missing.size}\")\n",
    "print(f\"Missing values: {np.isnan(X_missing).sum()} ({np.isnan(X_missing).sum()/X_missing.size*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# Method 1: KNN Imputation\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "X_knn_imputed = knn_imputer.fit_transform(X_missing)\n",
    "\n",
    "# Method 2: K-Means based imputation (manual implementation)\n",
    "def kmeans_imputation(X, n_clusters=5):\n",
    "    X_imputed = X.copy()\n",
    "    \n",
    "    # First pass: fill with column means for initial clustering\n",
    "    col_means = np.nanmean(X, axis=0)\n",
    "    for i in range(X.shape[1]):\n",
    "        X_imputed[np.isnan(X_imputed[:, i]), i] = col_means[i]\n",
    "    \n",
    "    # Cluster the data\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(X_imputed)\n",
    "    \n",
    "    # Impute based on cluster means\n",
    "    X_final = X.copy()\n",
    "    for cluster_id in range(n_clusters):\n",
    "        cluster_mask = clusters == cluster_id\n",
    "        cluster_means = np.nanmean(X[cluster_mask], axis=0)\n",
    "        \n",
    "        for i in range(X.shape[1]):\n",
    "            missing_in_cluster = np.isnan(X[:, i]) & cluster_mask\n",
    "            X_final[missing_in_cluster, i] = cluster_means[i]\n",
    "    \n",
    "    return X_final\n",
    "\n",
    "X_kmeans_imputed = kmeans_imputation(X_missing, n_clusters=5)\n",
    "\n",
    "# Calculate imputation errors\n",
    "missing_indices = np.where(missing_mask)\n",
    "knn_error = np.mean((X_complete[missing_indices] - X_knn_imputed[missing_indices])**2)\n",
    "kmeans_error = np.mean((X_complete[missing_indices] - X_kmeans_imputed[missing_indices])**2)\n",
    "\n",
    "print(f\"KNN Imputation MSE: {knn_error:.3f}\")\n",
    "print(f\"K-Means Imputation MSE: {kmeans_error:.3f}\")\n",
    "print()\n",
    "\n",
    "# Visualize imputation quality for first two features\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# Original complete data\n",
    "axes[0].scatter(X_complete[:, 0], X_complete[:, 1], alpha=0.5, s=30)\n",
    "axes[0].set_title('Original Complete Data', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "\n",
    "# KNN imputation\n",
    "axes[1].scatter(X_complete[:, 0], X_complete[:, 1], alpha=0.3, s=20, label='Original', color='gray')\n",
    "imputed_mask = missing_mask[:, 0] | missing_mask[:, 1]\n",
    "axes[1].scatter(X_knn_imputed[imputed_mask, 0], X_knn_imputed[imputed_mask, 1], \n",
    "                alpha=0.8, s=50, label='KNN Imputed', color='red', marker='^')\n",
    "axes[1].set_title(f'KNN Imputation (MSE: {knn_error:.3f})', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Feature 1')\n",
    "axes[1].set_ylabel('Feature 2')\n",
    "axes[1].legend()\n",
    "\n",
    "# K-Means imputation\n",
    "axes[2].scatter(X_complete[:, 0], X_complete[:, 1], alpha=0.3, s=20, label='Original', color='gray')\n",
    "axes[2].scatter(X_kmeans_imputed[imputed_mask, 0], X_kmeans_imputed[imputed_mask, 1], \n",
    "                alpha=0.8, s=50, label='K-Means Imputed', color='blue', marker='s')\n",
    "axes[2].set_title(f'K-Means Imputation (MSE: {kmeans_error:.3f})', fontsize=12, fontweight='bold')\n",
    "axes[2].set_xlabel('Feature 1')\n",
    "axes[2].set_ylabel('Feature 2')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ KNN typically provides better imputation by using local neighborhood information!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Runtime Comparison\n",
    "\n",
    "Let's compare the computational complexity of both algorithms with increasing dataset sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different dataset sizes\n",
    "sample_sizes = [100, 500, 1000, 2000, 5000]\n",
    "n_features = 10\n",
    "k = 5\n",
    "\n",
    "results = {\n",
    "    'n_samples': [],\n",
    "    'kmeans_fit': [],\n",
    "    'kmeans_predict': [],\n",
    "    'knn_fit': [],\n",
    "    'knn_predict': []\n",
    "}\n",
    "\n",
    "print(\"Running runtime benchmarks...\\n\")\n",
    "\n",
    "for n in sample_sizes:\n",
    "    print(f\"Testing with {n} samples...\")\n",
    "    \n",
    "    # Generate data\n",
    "    X, y = make_classification(n_samples=n, n_features=n_features, random_state=42)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    results['n_samples'].append(n)\n",
    "    \n",
    "    # K-Means timing\n",
    "    start = time.time()\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_train)\n",
    "    results['kmeans_fit'].append(time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    _ = kmeans.predict(X_test)\n",
    "    results['kmeans_predict'].append(time.time() - start)\n",
    "    \n",
    "    # KNN timing\n",
    "    start = time.time()\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    results['knn_fit'].append(time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    _ = knn.predict(X_test)\n",
    "    results['knn_predict'].append(time.time() - start)\n",
    "\n",
    "# Convert to DataFrame for easier plotting\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Training time\n",
    "axes[0].plot(df_results['n_samples'], df_results['kmeans_fit'], \n",
    "             marker='o', linewidth=2, markersize=8, label='K-Means Fit')\n",
    "axes[0].plot(df_results['n_samples'], df_results['knn_fit'], \n",
    "             marker='s', linewidth=2, markersize=8, label='KNN Fit')\n",
    "axes[0].set_xlabel('Number of Samples', fontsize=12)\n",
    "axes[0].set_ylabel('Time (seconds)', fontsize=12)\n",
    "axes[0].set_title('Training Time Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Prediction time\n",
    "axes[1].plot(df_results['n_samples'], df_results['kmeans_predict'], \n",
    "             marker='o', linewidth=2, markersize=8, label='K-Means Predict')\n",
    "axes[1].plot(df_results['n_samples'], df_results['knn_predict'], \n",
    "             marker='s', linewidth=2, markersize=8, label='KNN Predict')\n",
    "axes[1].set_xlabel('Number of Samples', fontsize=12)\n",
    "axes[1].set_ylabel('Time (seconds)', fontsize=12)\n",
    "axes[1].set_title('Prediction Time Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RUNTIME SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(df_results.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ“Š Key Observations:\")\n",
    "print(\"  â€¢ K-Means: Slow training (iterative), FAST prediction (just find nearest centroid)\")\n",
    "print(\"  â€¢ KNN: INSTANT training (lazy learner), slow prediction (searches all training data)\")\n",
    "print(\"  â€¢ KNN prediction time grows with training set size (linear complexity)\")\n",
    "print(\"  â€¢ K-Means prediction time stays constant (independent of training size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Summary: When to Use Which?\n",
    "\n",
    "### Use K-Means when:\n",
    "- âœ“ You have **unlabeled data** and want to discover patterns\n",
    "- âœ“ You need **fast predictions** after training\n",
    "- âœ“ You want to do **customer segmentation**, image compression, or feature engineering\n",
    "- âœ“ You can define the number of clusters upfront\n",
    "\n",
    "### Use KNN when:\n",
    "- âœ“ You have **labeled data** and want to make predictions\n",
    "- âœ“ You need both **classification and regression** capabilities\n",
    "- âœ“ You want to **impute missing values** effectively\n",
    "- âœ“ You need a simple, interpretable model\n",
    "- âœ“ Training speed is more important than prediction speed\n",
    "\n",
    "### Key Differences:\n",
    "\n",
    "| Aspect | K-Means | KNN |\n",
    "|--------|---------|-----|\n",
    "| **Learning Type** | Unsupervised | Supervised |\n",
    "| **Training Time** | Slow (iterative) | Instant (lazy) |\n",
    "| **Prediction Time** | Fast (O(k)) | Slow (O(n)) |\n",
    "| **Use Cases** | Clustering, segmentation | Classification, regression, imputation |\n",
    "| **Requires Labels** | No | Yes |\n",
    "| **Output** | Cluster assignments | Class labels or continuous values |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "categories = ['Unsupervised\\nLearning', 'Classification', 'Regression', \n",
    "              'Fast\\nPrediction', 'Missing Value\\nImputation']\n",
    "kmeans_scores = [1.0, 0.1, 0.0, 1.0, 0.6]  # Capability scores\n",
    "knn_scores = [0.0, 1.0, 1.0, 0.3, 1.0]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, kmeans_scores, width, label='K-Means', \n",
    "               color='steelblue', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, knn_scores, width, label='KNN', \n",
    "               color='coral', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Capability Score', fontsize=12)\n",
    "ax.set_title('K-Means vs. KNN: Capability Comparison', fontsize=16, fontweight='bold', pad=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories, fontsize=11)\n",
    "ax.legend(fontsize=12)\n",
    "ax.set_ylim(0, 1.2)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0.1:\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.1f}',\n",
    "                   ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸŽ¯ Choose the right tool for your specific problem!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
