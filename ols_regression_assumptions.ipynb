{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary Least Squares (OLS) Regression\n",
    "\n",
    "## Complete Guide: Understanding OLS and Its Assumptions\n",
    "\n",
    "This notebook provides a comprehensive, visual explanation of:\n",
    "1. How OLS works\n",
    "2. The key assumptions (Gauss-Markov conditions)\n",
    "3. What happens when assumptions are violated\n",
    "4. How to detect violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Styling\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ“ Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. How OLS Works: Minimizing the Sum of Squared Residuals\n",
    "\n",
    "OLS finds the line that **minimizes the sum of squared residuals** (errors).\n",
    "\n",
    "**Goal:** Find the best Î²â‚€ (intercept) and Î²â‚ (slope) for:\n",
    "```\n",
    "y = Î²â‚€ + Î²â‚x + Îµ\n",
    "```\n",
    "\n",
    "Where:\n",
    "- **y** = dependent variable (what we predict)\n",
    "- **x** = independent variable (predictor)\n",
    "- **Îµ** = residuals (errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate simple dataset\n",
    "np.random.seed(42)\n",
    "n = 50\n",
    "x = np.linspace(0, 10, n)\n",
    "y_true = 2 + 1.5 * x\n",
    "y = y_true + np.random.normal(0, 2, n)  # Add noise\n",
    "\n",
    "# Fit OLS model\n",
    "X = x.reshape(-1, 1)\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "residuals = y - y_pred\n",
    "\n",
    "print(f\"True equation:      y = 2.0 + 1.5x\")\n",
    "print(f\"Estimated equation: y = {model.intercept_:.2f} + {model.coef_[0]:.2f}x\")\n",
    "print(f\"RÂ² Score: {model.score(X, y):.4f}\")\n",
    "\n",
    "# Visualize OLS\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Data and regression line\n",
    "axes[0].scatter(x, y, alpha=0.6, s=80, label='Observed data', color='steelblue')\n",
    "axes[0].plot(x, y_pred, 'r-', linewidth=2, label='OLS regression line')\n",
    "axes[0].plot(x, y_true, 'g--', linewidth=2, alpha=0.5, label='True relationship')\n",
    "axes[0].set_xlabel('X (Independent Variable)', fontsize=12)\n",
    "axes[0].set_ylabel('Y (Dependent Variable)', fontsize=12)\n",
    "axes[0].set_title('OLS Regression Line', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Residuals visualization\n",
    "axes[1].scatter(x, y, alpha=0.6, s=80, color='steelblue', label='Observed data')\n",
    "axes[1].plot(x, y_pred, 'r-', linewidth=2, label='OLS line')\n",
    "\n",
    "# Draw residual lines\n",
    "for i in range(0, n, 3):  # Show every 3rd residual to avoid clutter\n",
    "    axes[1].plot([x[i], x[i]], [y[i], y_pred[i]], 'k--', alpha=0.4, linewidth=1)\n",
    "\n",
    "axes[1].set_xlabel('X', fontsize=12)\n",
    "axes[1].set_ylabel('Y', fontsize=12)\n",
    "axes[1].set_title('Residuals: Distance from Line', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ OLS minimizes the sum of squared residuals (vertical distances)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. The OLS Assumptions (Gauss-Markov Conditions)\n",
    "\n",
    "For OLS to provide the **Best Linear Unbiased Estimator (BLUE)**, the following assumptions must hold:\n",
    "\n",
    "### Core Assumptions:\n",
    "1. **Linearity**: The relationship is linear in parameters\n",
    "2. **Zero Mean of Residuals**: E(Îµ) = 0\n",
    "3. **No Correlation between X and Residuals**: Cov(X, Îµ) = 0\n",
    "4. **Homoscedasticity**: Constant variance of residuals (Var(Îµ) = ÏƒÂ²)\n",
    "5. **No Autocorrelation**: Residuals are uncorrelated (Cov(Îµáµ¢, Îµâ±¼) = 0 for i â‰  j)\n",
    "6. **Normality of Residuals**: Îµ ~ N(0, ÏƒÂ²) (needed for inference)\n",
    "7. **No Multicollinearity**: Independent variables are uncorrelated (for multiple regression)\n",
    "\n",
    "Let's examine each assumption!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Assumption 1: Linearity\n",
    "\n",
    "**Requirement:** The relationship between X and Y must be linear (in parameters).\n",
    "\n",
    "**What happens if violated?** Predictions will be biased and inaccurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create non-linear relationship\n",
    "x_nl = np.linspace(0, 10, 100)\n",
    "y_nl_true = 2 + 3*x_nl - 0.3*x_nl**2  # Quadratic relationship\n",
    "y_nl = y_nl_true + np.random.normal(0, 2, 100)\n",
    "\n",
    "# Fit linear model (wrong!)\n",
    "X_nl = x_nl.reshape(-1, 1)\n",
    "model_linear = LinearRegression().fit(X_nl, y_nl)\n",
    "y_nl_pred_linear = model_linear.predict(X_nl)\n",
    "residuals_nl = y_nl - y_nl_pred_linear\n",
    "\n",
    "# Fit correct quadratic model\n",
    "X_nl_poly = np.column_stack([x_nl, x_nl**2])\n",
    "model_poly = LinearRegression().fit(X_nl_poly, y_nl)\n",
    "y_nl_pred_poly = model_poly.predict(X_nl_poly)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Plot 1: Wrong linear fit\n",
    "axes[0].scatter(x_nl, y_nl, alpha=0.5, s=30, label='Data')\n",
    "axes[0].plot(x_nl, y_nl_pred_linear, 'r-', linewidth=2, label='Linear fit (WRONG)')\n",
    "axes[0].plot(x_nl, y_nl_true, 'g--', linewidth=2, alpha=0.7, label='True quadratic')\n",
    "axes[0].set_xlabel('X')\n",
    "axes[0].set_ylabel('Y')\n",
    "axes[0].set_title('âŒ Linearity Violated', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Residual plot shows pattern (BAD!)\n",
    "axes[1].scatter(y_nl_pred_linear, residuals_nl, alpha=0.5, s=30)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Fitted Values')\n",
    "axes[1].set_ylabel('Residuals')\n",
    "axes[1].set_title('âŒ Residual Pattern â†’ Non-linearity', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: Correct polynomial fit\n",
    "axes[2].scatter(x_nl, y_nl, alpha=0.5, s=30, label='Data')\n",
    "axes[2].plot(x_nl, y_nl_pred_poly, 'r-', linewidth=2, label='Quadratic fit (CORRECT)')\n",
    "axes[2].plot(x_nl, y_nl_true, 'g--', linewidth=2, alpha=0.7, label='True quadratic')\n",
    "axes[2].set_xlabel('X')\n",
    "axes[2].set_ylabel('Y')\n",
    "axes[2].set_title('âœ“ Correct Model', fontsize=12, fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ” Detection: Look for patterns in residual plots\")\n",
    "print(\"ðŸ› ï¸  Solution: Transform variables or use polynomial regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Assumption 2: Zero Mean of Residuals\n",
    "\n",
    "**Requirement:** E(Îµ) = 0 â†’ Residuals should average to zero.\n",
    "\n",
    "**Good news:** OLS automatically ensures this by including an intercept!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check mean of residuals from our earlier model\n",
    "print(f\"Mean of residuals: {np.mean(residuals):.10f}\")\n",
    "print(f\"(Essentially zero, due to floating-point precision)\\n\")\n",
    "\n",
    "# Visualize distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(residuals, bins=20, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "axes[0].axvline(x=np.mean(residuals), color='r', linestyle='--', linewidth=2, \n",
    "                label=f'Mean = {np.mean(residuals):.4f}')\n",
    "axes[0].set_xlabel('Residuals', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of Residuals', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(residuals, vert=True)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', linewidth=2, label='Zero line')\n",
    "axes[1].set_ylabel('Residuals', fontsize=12)\n",
    "axes[1].set_title('Residual Box Plot', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ When model includes intercept, mean of residuals = 0 (by construction)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Assumption 3: No Correlation Between X and Residuals\n",
    "\n",
    "**Requirement:** Cov(X, Îµ) = 0 â†’ Residuals should be independent of X.\n",
    "\n",
    "**What happens if violated?** Estimates are biased (omitted variable bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation\n",
    "correlation = np.corrcoef(x, residuals)[0, 1]\n",
    "print(f\"Correlation(X, residuals) = {correlation:.10f}\")\n",
    "print(\"(Should be approximately zero)\\n\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x, residuals, alpha=0.6, s=60, color='steelblue')\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=2, label='Zero line')\n",
    "plt.xlabel('X (Independent Variable)', fontsize=12)\n",
    "plt.ylabel('Residuals', fontsize=12)\n",
    "plt.title(f'Residuals vs X (Correlation = {correlation:.4f})', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ No pattern â†’ Assumption satisfied\")\n",
    "print(\"âŒ Pattern or trend â†’ Omitted variable problem!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Assumption 4: Homoscedasticity (Constant Variance)\n",
    "\n",
    "**Requirement:** Var(Îµ) = ÏƒÂ² â†’ Variance of residuals should be constant across all X values.\n",
    "\n",
    "**What happens if violated (Heteroscedasticity)?**\n",
    "- Standard errors are incorrect\n",
    "- Confidence intervals and hypothesis tests are invalid\n",
    "- Estimates are still unbiased but not efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heteroscedastic data (variance increases with X)\n",
    "x_het = np.linspace(1, 10, 100)\n",
    "y_het = 2 + 1.5 * x_het + np.random.normal(0, 1, 100) * x_het  # Variance grows with x!\n",
    "\n",
    "# Fit model\n",
    "X_het = x_het.reshape(-1, 1)\n",
    "model_het = LinearRegression().fit(X_het, y_het)\n",
    "y_het_pred = model_het.predict(X_het)\n",
    "residuals_het = y_het - y_het_pred\n",
    "\n",
    "# Compare with homoscedastic data\n",
    "y_homo = 2 + 1.5 * x_het + np.random.normal(0, 2, 100)  # Constant variance\n",
    "model_homo = LinearRegression().fit(X_het, y_homo)\n",
    "y_homo_pred = model_homo.predict(X_het)\n",
    "residuals_homo = y_homo - y_homo_pred\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Homoscedastic case\n",
    "axes[0, 0].scatter(x_het, y_homo, alpha=0.5, s=30, color='green')\n",
    "axes[0, 0].plot(x_het, y_homo_pred, 'r-', linewidth=2)\n",
    "axes[0, 0].set_xlabel('X')\n",
    "axes[0, 0].set_ylabel('Y')\n",
    "axes[0, 0].set_title('âœ“ Homoscedastic Data', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "axes[0, 1].scatter(y_homo_pred, residuals_homo, alpha=0.5, s=30, color='green')\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Fitted Values')\n",
    "axes[0, 1].set_ylabel('Residuals')\n",
    "axes[0, 1].set_title('âœ“ Constant Variance', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Heteroscedastic case\n",
    "axes[1, 0].scatter(x_het, y_het, alpha=0.5, s=30, color='red')\n",
    "axes[1, 0].plot(x_het, y_het_pred, 'r-', linewidth=2)\n",
    "axes[1, 0].set_xlabel('X')\n",
    "axes[1, 0].set_ylabel('Y')\n",
    "axes[1, 0].set_title('âŒ Heteroscedastic Data', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "axes[1, 1].scatter(y_het_pred, residuals_het, alpha=0.5, s=30, color='red')\n",
    "axes[1, 1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Fitted Values')\n",
    "axes[1, 1].set_ylabel('Residuals')\n",
    "axes[1, 1].set_title('âŒ Variance Increases (Funnel Shape)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ” Detection: Look for funnel/cone shape in residual plot\")\n",
    "print(\"ðŸ› ï¸  Solutions:\")\n",
    "print(\"   â€¢ Transform Y (e.g., log transform)\")\n",
    "print(\"   â€¢ Use Weighted Least Squares (WLS)\")\n",
    "print(\"   â€¢ Use robust standard errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Assumption 5: No Autocorrelation\n",
    "\n",
    "**Requirement:** Residuals should be uncorrelated â†’ Cov(Îµáµ¢, Îµâ±¼) = 0 for i â‰  j.\n",
    "\n",
    "**What happens if violated?**\n",
    "- Common in time series data\n",
    "- Standard errors are underestimated\n",
    "- Over-confident predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create autocorrelated residuals (time series)\n",
    "n_time = 100\n",
    "t = np.arange(n_time)\n",
    "\n",
    "# Data WITH autocorrelation\n",
    "np.random.seed(42)\n",
    "errors_auto = np.zeros(n_time)\n",
    "errors_auto[0] = np.random.normal(0, 1)\n",
    "for i in range(1, n_time):\n",
    "    errors_auto[i] = 0.8 * errors_auto[i-1] + np.random.normal(0, 1)  # AR(1) process\n",
    "\n",
    "y_auto = 2 + 0.5 * t + errors_auto\n",
    "\n",
    "# Data WITHOUT autocorrelation\n",
    "errors_no_auto = np.random.normal(0, 2, n_time)\n",
    "y_no_auto = 2 + 0.5 * t + errors_no_auto\n",
    "\n",
    "# Fit models\n",
    "T = t.reshape(-1, 1)\n",
    "model_auto = LinearRegression().fit(T, y_auto)\n",
    "residuals_auto = y_auto - model_auto.predict(T)\n",
    "\n",
    "model_no_auto = LinearRegression().fit(T, y_no_auto)\n",
    "residuals_no_auto = y_no_auto - model_no_auto.predict(T)\n",
    "\n",
    "# Calculate autocorrelation (lag 1)\n",
    "auto_corr = np.corrcoef(residuals_auto[:-1], residuals_auto[1:])[0, 1]\n",
    "no_auto_corr = np.corrcoef(residuals_no_auto[:-1], residuals_no_auto[1:])[0, 1]\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# No autocorrelation\n",
    "axes[0, 0].plot(t, residuals_no_auto, marker='o', alpha=0.6, linestyle='-', markersize=4)\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Time')\n",
    "axes[0, 0].set_ylabel('Residuals')\n",
    "axes[0, 0].set_title('âœ“ No Autocorrelation', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "axes[0, 1].scatter(residuals_no_auto[:-1], residuals_no_auto[1:], alpha=0.5, s=30, color='green')\n",
    "axes[0, 1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[0, 1].axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[0, 1].set_xlabel('Residual at t')\n",
    "axes[0, 1].set_ylabel('Residual at t+1')\n",
    "axes[0, 1].set_title(f'âœ“ Lag Plot (r = {no_auto_corr:.3f})', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# WITH autocorrelation\n",
    "axes[1, 0].plot(t, residuals_auto, marker='o', alpha=0.6, linestyle='-', \n",
    "                markersize=4, color='red')\n",
    "axes[1, 0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Time')\n",
    "axes[1, 0].set_ylabel('Residuals')\n",
    "axes[1, 0].set_title('âŒ Autocorrelation Present', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "axes[1, 1].scatter(residuals_auto[:-1], residuals_auto[1:], alpha=0.5, s=30, color='red')\n",
    "axes[1, 1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "# Add trend line\n",
    "z = np.polyfit(residuals_auto[:-1], residuals_auto[1:], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[1, 1].plot(residuals_auto[:-1], p(residuals_auto[:-1]), \"b--\", linewidth=2, alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Residual at t')\n",
    "axes[1, 1].set_ylabel('Residual at t+1')\n",
    "axes[1, 1].set_title(f'âŒ Lag Plot (r = {auto_corr:.3f})', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ” Detection: Durbin-Watson test, ACF/PACF plots, or lag plots\")\n",
    "print(\"ðŸ› ï¸  Solutions:\")\n",
    "print(\"   â€¢ Add lagged variables\")\n",
    "print(\"   â€¢ Use time series models (ARIMA, etc.)\")\n",
    "print(\"   â€¢ Use Newey-West standard errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Assumption 6: Normality of Residuals\n",
    "\n",
    "**Requirement:** Îµ ~ N(0, ÏƒÂ²) â†’ Residuals should be normally distributed.\n",
    "\n",
    "**What happens if violated?**\n",
    "- Estimates remain unbiased\n",
    "- Hypothesis tests and confidence intervals may be invalid\n",
    "- Less critical with large samples (Central Limit Theorem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with non-normal residuals\n",
    "x_norm = np.linspace(0, 10, 100)\n",
    "\n",
    "# Normal residuals\n",
    "errors_normal = np.random.normal(0, 2, 100)\n",
    "y_normal = 2 + 1.5 * x_norm + errors_normal\n",
    "\n",
    "# Non-normal residuals (skewed)\n",
    "errors_skewed = np.random.exponential(2, 100) - 2  # Right-skewed\n",
    "y_skewed = 2 + 1.5 * x_norm + errors_skewed\n",
    "\n",
    "# Fit models\n",
    "X_norm = x_norm.reshape(-1, 1)\n",
    "model_normal = LinearRegression().fit(X_norm, y_normal)\n",
    "residuals_normal = y_normal - model_normal.predict(X_norm)\n",
    "\n",
    "model_skewed = LinearRegression().fit(X_norm, y_skewed)\n",
    "residuals_skewed = y_skewed - model_skewed.predict(X_norm)\n",
    "\n",
    "# Statistical tests\n",
    "from scipy.stats import shapiro, probplot\n",
    "\n",
    "stat_normal, p_normal = shapiro(residuals_normal)\n",
    "stat_skewed, p_skewed = shapiro(residuals_skewed)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# Normal residuals\n",
    "axes[0, 0].hist(residuals_normal, bins=20, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Residuals')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title(f'âœ“ Normal Residuals\\nShapiro p={p_normal:.4f}', \n",
    "                     fontsize=11, fontweight='bold')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "probplot(residuals_normal, dist=\"norm\", plot=axes[0, 1])\n",
    "axes[0, 1].set_title('âœ“ Q-Q Plot: Points on Line', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "axes[0, 2].boxplot(residuals_normal)\n",
    "axes[0, 2].set_ylabel('Residuals')\n",
    "axes[0, 2].set_title('âœ“ Symmetric Distribution', fontsize=11, fontweight='bold')\n",
    "axes[0, 2].grid(alpha=0.3)\n",
    "\n",
    "# Skewed residuals\n",
    "axes[1, 0].hist(residuals_skewed, bins=20, alpha=0.7, color='red', edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Residuals')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title(f'âŒ Skewed Residuals\\nShapiro p={p_skewed:.4f}', \n",
    "                     fontsize=11, fontweight='bold')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "probplot(residuals_skewed, dist=\"norm\", plot=axes[1, 1])\n",
    "axes[1, 1].set_title('âŒ Q-Q Plot: Deviation from Line', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "axes[1, 2].boxplot(residuals_skewed)\n",
    "axes[1, 2].set_ylabel('Residuals')\n",
    "axes[1, 2].set_title('âŒ Skewed with Outliers', fontsize=11, fontweight='bold')\n",
    "axes[1, 2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ” Detection: Shapiro-Wilk test, Q-Q plot, histogram\")\n",
    "print(\"   â€¢ Shapiro-Wilk p > 0.05 â†’ Likely normal\")\n",
    "print(\"   â€¢ Q-Q plot points on line â†’ Normal\")\n",
    "print(\"\\nðŸ› ï¸  Solutions:\")\n",
    "print(\"   â€¢ Transform Y (Box-Cox, log, sqrt)\")\n",
    "print(\"   â€¢ Remove outliers (carefully!)\")\n",
    "print(\"   â€¢ Use robust regression methods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Assumption 7: No Multicollinearity (Multiple Regression)\n",
    "\n",
    "**Requirement:** Independent variables should not be highly correlated with each other.\n",
    "\n",
    "**What happens if violated?**\n",
    "- Unstable coefficient estimates\n",
    "- Large standard errors\n",
    "- Difficult to determine individual variable effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multicollinear data\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "\n",
    "# Independent variables\n",
    "X1 = np.random.randn(n)\n",
    "X2 = np.random.randn(n)\n",
    "X3 = 0.9 * X1 + 0.1 * np.random.randn(n)  # Highly correlated with X1!\n",
    "\n",
    "# True relationship: y = 2 + 3*X1 + 4*X2 + noise\n",
    "y_multi = 2 + 3*X1 + 4*X2 + np.random.randn(n)\n",
    "\n",
    "# Case 1: No multicollinearity (X1 and X2)\n",
    "X_good = np.column_stack([X1, X2])\n",
    "model_good = LinearRegression().fit(X_good, y_multi)\n",
    "\n",
    "# Case 2: WITH multicollinearity (X1 and X3)\n",
    "X_bad = np.column_stack([X1, X3])\n",
    "model_bad = LinearRegression().fit(X_bad, y_multi)\n",
    "\n",
    "print(\"ðŸ” Multicollinearity Check:\\n\")\n",
    "print(f\"Correlation(X1, X2): {np.corrcoef(X1, X2)[0,1]:.4f} âœ“ (Low)\")\n",
    "print(f\"Correlation(X1, X3): {np.corrcoef(X1, X3)[0,1]:.4f} âŒ (High!)\\n\")\n",
    "\n",
    "print(\"Model WITHOUT multicollinearity (X1, X2):\")\n",
    "print(f\"  Î²â‚ = {model_good.coef_[0]:.3f} (should be ~3)\")\n",
    "print(f\"  Î²â‚‚ = {model_good.coef_[1]:.3f} (should be ~4)\")\n",
    "print(f\"  RÂ² = {model_good.score(X_good, y_multi):.4f}\\n\")\n",
    "\n",
    "print(\"Model WITH multicollinearity (X1, X3):\")\n",
    "print(f\"  Î²â‚ = {model_bad.coef_[0]:.3f} (unstable!)\")\n",
    "print(f\"  Î²â‚ƒ = {model_bad.coef_[1]:.3f} (unstable!)\")\n",
    "print(f\"  RÂ² = {model_bad.score(X_bad, y_multi):.4f}\")\n",
    "print(\"  â†’ Coefficients are unreliable!\\n\")\n",
    "\n",
    "# Visualize correlation\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Good: X1 vs X2\n",
    "axes[0].scatter(X1, X2, alpha=0.6, s=40, color='green')\n",
    "axes[0].set_xlabel('X1')\n",
    "axes[0].set_ylabel('X2')\n",
    "axes[0].set_title(f'âœ“ No Multicollinearity\\nr = {np.corrcoef(X1, X2)[0,1]:.3f}', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Bad: X1 vs X3\n",
    "axes[1].scatter(X1, X3, alpha=0.6, s=40, color='red')\n",
    "# Add trend line\n",
    "z = np.polyfit(X1, X3, 1)\n",
    "p = np.poly1d(z)\n",
    "axes[1].plot(np.sort(X1), p(np.sort(X1)), \"b--\", linewidth=2)\n",
    "axes[1].set_xlabel('X1')\n",
    "axes[1].set_ylabel('X3')\n",
    "axes[1].set_title(f'âŒ High Multicollinearity\\nr = {np.corrcoef(X1, X3)[0,1]:.3f}', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = np.corrcoef([X1, X2, X3])\n",
    "im = axes[2].imshow(corr_matrix, cmap='RdYlGn_r', vmin=-1, vmax=1)\n",
    "axes[2].set_xticks([0, 1, 2])\n",
    "axes[2].set_yticks([0, 1, 2])\n",
    "axes[2].set_xticklabels(['X1', 'X2', 'X3'])\n",
    "axes[2].set_yticklabels(['X1', 'X2', 'X3'])\n",
    "axes[2].set_title('Correlation Matrix', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add correlation values\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        text = axes[2].text(j, i, f'{corr_matrix[i, j]:.2f}',\n",
    "                           ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
    "\n",
    "plt.colorbar(im, ax=axes[2])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ” Detection: Variance Inflation Factor (VIF), correlation matrix\")\n",
    "print(\"   â€¢ VIF > 10 â†’ Severe multicollinearity\")\n",
    "print(\"   â€¢ |correlation| > 0.8 â†’ Potential problem\")\n",
    "print(\"\\nðŸ› ï¸  Solutions:\")\n",
    "print(\"   â€¢ Remove one of the correlated variables\")\n",
    "print(\"   â€¢ Combine correlated variables (PCA)\")\n",
    "print(\"   â€¢ Use Ridge regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Complete Diagnostic Plot\n",
    "\n",
    "A comprehensive residual analysis to check all assumptions at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our original good model\n",
    "from scipy import stats as sp_stats\n",
    "\n",
    "# Standardized residuals\n",
    "residuals_std = (residuals - np.mean(residuals)) / np.std(residuals)\n",
    "\n",
    "# Create comprehensive diagnostic plot\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Residuals vs Fitted\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax1.scatter(y_pred, residuals, alpha=0.6, s=50)\n",
    "ax1.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "ax1.set_xlabel('Fitted Values', fontsize=11)\n",
    "ax1.set_ylabel('Residuals', fontsize=11)\n",
    "ax1.set_title('1. Residuals vs Fitted (Check: Linearity, Homoscedasticity)', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# 2. Q-Q Plot\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "sp_stats.probplot(residuals, dist=\"norm\", plot=ax2)\n",
    "ax2.set_title('2. Q-Q Plot\\n(Check: Normality)', fontsize=11, fontweight='bold')\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# 3. Scale-Location (sqrt of standardized residuals)\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "ax3.scatter(y_pred, np.sqrt(np.abs(residuals_std)), alpha=0.6, s=50)\n",
    "ax3.set_xlabel('Fitted Values', fontsize=11)\n",
    "ax3.set_ylabel('âˆš|Standardized Residuals|', fontsize=11)\n",
    "ax3.set_title('3. Scale-Location\\n(Check: Homoscedasticity)', fontsize=11, fontweight='bold')\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "# 4. Residuals histogram\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "ax4.hist(residuals, bins=20, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "ax4.axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "ax4.set_xlabel('Residuals', fontsize=11)\n",
    "ax4.set_ylabel('Frequency', fontsize=11)\n",
    "ax4.set_title('4. Histogram\\n(Check: Normality)', fontsize=11, fontweight='bold')\n",
    "ax4.grid(alpha=0.3)\n",
    "\n",
    "# 5. Residuals vs X\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "ax5.scatter(x, residuals, alpha=0.6, s=50, color='purple')\n",
    "ax5.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "ax5.set_xlabel('X', fontsize=11)\n",
    "ax5.set_ylabel('Residuals', fontsize=11)\n",
    "ax5.set_title('5. Residuals vs X\\n(Check: Independence)', fontsize=11, fontweight='bold')\n",
    "ax5.grid(alpha=0.3)\n",
    "\n",
    "# 6. Residuals vs Order\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "ax6.plot(range(len(residuals)), residuals, marker='o', linestyle='-', \n",
    "         alpha=0.6, markersize=4, color='orange')\n",
    "ax6.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "ax6.set_xlabel('Observation Order', fontsize=11)\n",
    "ax6.set_ylabel('Residuals', fontsize=11)\n",
    "ax6.set_title('6. Residuals vs Order\\n(Check: Autocorrelation)', fontsize=11, fontweight='bold')\n",
    "ax6.grid(alpha=0.3)\n",
    "\n",
    "# 7. Box plot\n",
    "ax7 = fig.add_subplot(gs[2, 2])\n",
    "ax7.boxplot(residuals, vert=True)\n",
    "ax7.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "ax7.set_ylabel('Residuals', fontsize=11)\n",
    "ax7.set_title('7. Box Plot\\n(Check: Outliers)', fontsize=11, fontweight='bold')\n",
    "ax7.grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('OLS Regression Diagnostics', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Use these plots together to assess all OLS assumptions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Summary: OLS Assumptions Checklist\n",
    "\n",
    "### âœ… Quick Checklist\n",
    "\n",
    "| Assumption | What to Check | What You Want to See |\n",
    "|-----------|---------------|---------------------|\n",
    "| **1. Linearity** | Residuals vs Fitted plot | No pattern, random scatter |\n",
    "| **2. Zero Mean** | Mean of residuals | â‰ˆ 0 (automatic with intercept) |\n",
    "| **3. No X-Îµ Correlation** | Residuals vs X plot | No pattern, correlation â‰ˆ 0 |\n",
    "| **4. Homoscedasticity** | Residuals vs Fitted plot | Constant spread (no funnel) |\n",
    "| **5. No Autocorrelation** | Residuals vs Order plot | No pattern over time |\n",
    "| **6. Normality** | Q-Q plot, Shapiro test | Points on line, p > 0.05 |\n",
    "| **7. No Multicollinearity** | Correlation matrix, VIF | Low correlations, VIF < 10 |\n",
    "\n",
    "### ðŸŽ¯ What to Do When Assumptions Fail\n",
    "\n",
    "**Non-linearity**\n",
    "- Transform variables (log, polynomial, etc.)\n",
    "- Use non-linear models\n",
    "\n",
    "**Heteroscedasticity**\n",
    "- Transform Y (log, Box-Cox)\n",
    "- Use Weighted Least Squares (WLS)\n",
    "- Use robust standard errors\n",
    "\n",
    "**Autocorrelation**\n",
    "- Add time lags\n",
    "- Use time series models (ARIMA)\n",
    "- Use Newey-West standard errors\n",
    "\n",
    "**Non-normality**\n",
    "- Transform Y\n",
    "- Use robust regression\n",
    "- Remove outliers (carefully!)\n",
    "- Remember: Less critical with large samples\n",
    "\n",
    "**Multicollinearity**\n",
    "- Remove correlated variables\n",
    "- Use PCA\n",
    "- Use Ridge/Lasso regression\n",
    "\n",
    "### ðŸ“Š Key Takeaways\n",
    "\n",
    "1. **OLS is BLUE** (Best Linear Unbiased Estimator) **only when assumptions hold**\n",
    "2. **Always check residual plots** - they reveal assumption violations\n",
    "3. **Some violations are worse than others:**\n",
    "   - Omitted variables â†’ Biased estimates (serious!)\n",
    "   - Heteroscedasticity â†’ Invalid inference (fixable)\n",
    "   - Non-normality â†’ Less critical with large n\n",
    "4. **Perfect assumptions are rare** - focus on major violations\n",
    "5. **Multiple checks are better** - no single test is definitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final visualization: Assumption violations summary\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "violation_types = [\n",
    "    'Good Model',\n",
    "    'Non-linearity',\n",
    "    'Heteroscedasticity',\n",
    "    'Autocorrelation',\n",
    "    'Non-normality',\n",
    "    'Outliers'\n",
    "]\n",
    "\n",
    "# Generate example patterns for each\n",
    "np.random.seed(42)\n",
    "x_demo = np.linspace(0, 10, 100)\n",
    "\n",
    "patterns = [\n",
    "    np.random.normal(0, 1, 100),  # Good\n",
    "    (x_demo - 5)**2 - 5,  # Non-linear\n",
    "    np.random.normal(0, 1, 100) * (1 + 0.3*x_demo),  # Heteroscedastic\n",
    "    np.cumsum(np.random.normal(0, 0.3, 100)),  # Autocorrelated\n",
    "    np.concatenate([np.random.normal(-1, 0.5, 70), np.random.normal(3, 0.5, 30)]),  # Skewed\n",
    "    np.concatenate([np.random.normal(0, 1, 95), [8, -7, 9, -8, 7]])  # With outliers\n",
    "]\n",
    "\n",
    "colors = ['green', 'red', 'red', 'red', 'red', 'red']\n",
    "symbols = ['âœ“', 'âŒ', 'âŒ', 'âŒ', 'âŒ', 'âŒ']\n",
    "\n",
    "for idx, (pattern, title, color, symbol) in enumerate(zip(patterns, violation_types, colors, symbols)):\n",
    "    if idx in [0, 1, 2, 5]:  # Scatter plots\n",
    "        axes[idx].scatter(x_demo[:len(pattern)], pattern, alpha=0.5, s=30, color=color)\n",
    "    else:  # Line plots for time-based\n",
    "        axes[idx].plot(range(len(pattern)), pattern, alpha=0.6, color=color)\n",
    "    \n",
    "    axes[idx].axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    axes[idx].set_title(f'{symbol} {title}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Visual Guide to OLS Assumption Violations', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"REMEMBER: Check your assumptions, check your residuals!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
